{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Importing Dependencies & Data"
      ],
      "metadata": {
        "id": "MurhUPi76cyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split as tts"
      ],
      "metadata": {
        "id": "Z5EmPRNC6Zyr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BostonHousingData(Dataset):\n",
        "\n",
        "  def __init__(self, csvfile='data/boston_housing.csv'):\n",
        "\n",
        "    super(Dataset, self).__init__()\n",
        "\n",
        "    data = pd.read_csv(csvfile)\n",
        "    target = 'medv'\n",
        "    X, y = data.drop([target], axis=1).values, data[target].values\n",
        "    self.X, self.y = torch.from_numpy(X), torch.from_numpy(y)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "7c5Y9N91_yid"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = BostonHousingData()"
      ],
      "metadata": {
        "id": "vp9ktm3B79Gf"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rng = torch.Generator().manual_seed(42)"
      ],
      "metadata": {
        "id": "oHEHFgYLJWWa"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = random_split(dataset, [0.8, 0.2], rng)\n",
        "train_data, test_data = random_split(train_data, [0.8, 0.2], rng)"
      ],
      "metadata": {
        "id": "HpkknJ5hIFg4"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, shuffle=True)\n",
        "val_loader = DataLoader(val_data, shuffle=False)\n",
        "test_loader = DataLoader(test_data, shuffle=False)"
      ],
      "metadata": {
        "id": "JgFwXNdyKoae"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model"
      ],
      "metadata": {
        "id": "tI_slM5HMjJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(input_dim, 64)\n",
        "    self.fc2 = nn.Linear(64, 64)\n",
        "    self.fc3 = nn.Linear(64, output_dim)\n",
        "    self.do = nn.Dropout(0.3)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    h1 = self.fc1(x)\n",
        "    h1 = self.relu(h1)\n",
        "    h2 = self.fc2(h1)\n",
        "    h2 = self.relu(h2)\n",
        "    do = self.do(h1+h2)\n",
        "    yh = self.fc3(do)\n",
        "\n",
        "    return yh"
      ],
      "metadata": {
        "id": "XarYpRp2MkSa"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For changing the initialization function for any layer we can use for example:<br> <b>nn.init.xavier_uniform(fc1.weight)</b>\n",
        "<br><br> A second approach exists where we find layers within a network by treating them as attributes of a class. For this method we can use net.apply(init_function). Here we define the init_function. <a href='https://stackoverflow.com/questions/49433936/how-do-i-initialize-weights-in-pytorch'>Check more here</a>"
      ],
      "metadata": {
        "id": "yb__9gaJepsp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training"
      ],
      "metadata": {
        "id": "Bc5eU4QIcPs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(input_dim=dataset.X.shape[1], output_dim=1)\n"
      ],
      "metadata": {
        "id": "OGL9eKppcGEK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}